{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Offline Evals via Logs"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize Maxim SDK"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from typing import Dict, List\n",
                "from maxim import Maxim\n",
                "from maxim.models import (\n",
                "    LocalData,\n",
                "    YieldedOutput,\n",
                "    QueryBuilder,\n",
                ")\n",
                "from maxim.models.dataset import DataStructure\n",
                "\n",
                "# Initialize Maxim with prompt management enabled\n",
                "maxim = Maxim({\n",
                "    \"api_key\": os.getenv(\"MAXIM_API_KEY\"),\n",
                "    \"prompt_management\": True,  # Required for fetching prompts\n",
                "})\n",
                "\n",
                "WORKSPACE_ID = os.getenv(\"MAXIM_WORKSPACE_ID\")\n",
                "DATASET_ID = os.getenv(\"MAXIM_DATASET_ID\")  # For hosted dataset example\n",
                "PROMPT_ID = os.getenv(\"MAXIM_PROMPT_ID\")    # For prompt management example"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Local Dataset and Local Agent\n",
                "\n",
                "Define your test data and agent logic entirely in code."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define test data locally\n",
                "local_dataset: List[LocalData] = [\n",
                "    {\n",
                "        \"input\": \"What is the capital of France?\",\n",
                "        \"expected_output\": \"Paris\",\n",
                "    },\n",
                "    {\n",
                "        \"input\": \"Explain photosynthesis in one sentence.\",\n",
                "        \"expected_output\": \"A process where plants convert sunlight to energy\",\n",
                "    },\n",
                "]\n",
                "\n",
                "data_structure: DataStructure = {\n",
                "    \"input\": \"INPUT\",\n",
                "    \"expected_output\": \"EXPECTED_OUTPUT\",\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from openai import OpenAI\n",
                "\n",
                "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
                "\n",
                "def run_local_agent(data: LocalData) -> YieldedOutput:\n",
                "    \"\"\"\n",
                "    Your local agent implementation.\n",
                "    Called for each entry in the test dataset.\n",
                "    \"\"\"\n",
                "    user_input = data.get(\"Input\") or data.get(\"input\") or \"\"\n",
                "    \n",
                "    response = openai_client.chat.completions.create(\n",
                "        model=\"gpt-4o-mini\",\n",
                "        messages=[\n",
                "            {\"role\": \"system\", \"content\": \"You are a helpful assistant. Be concise.\"},\n",
                "            {\"role\": \"user\", \"content\": user_input}\n",
                "        ],\n",
                "        max_tokens=100,\n",
                "    )\n",
                "    \n",
                "    return YieldedOutput(data=response.choices[0].message.content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run test with local dataset + local agent\n",
                "result = (\n",
                "    maxim.create_test_run(\n",
                "        name=\"Local Dataset + Local Agent\",\n",
                "        in_workspace_id=WORKSPACE_ID\n",
                "    )\n",
                "    .with_data(local_dataset)\n",
                "    .with_data_structure(data_structure)\n",
                "    .yields_output(run_local_agent)\n",
                "    .with_evaluators(\"Clarity\", \"Output Relevance\")\n",
                "    .run()\n",
                ")\n",
                "\n",
                "print(f\"View results: {result.test_run_result.link}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Hosted Dataset on Maxim and Local Agent\n",
                "\n",
                "Use a dataset stored on Maxim's platform. Pass the dataset ID instead of local data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run test with hosted dataset\n",
                "result = (\n",
                "    maxim.create_test_run(\n",
                "        name=\"Hosted Dataset + Local Agent\",\n",
                "        in_workspace_id=WORKSPACE_ID\n",
                "    )\n",
                "    .with_data(DATASET_ID)  # Pass dataset ID from Maxim\n",
                "    .yields_output(run_local_agent)\n",
                "    .with_evaluators(\"Clarity\", \"Output Relevance\")\n",
                "    .run()\n",
                ")\n",
                "\n",
                "print(f\"View results: {result.test_run_result.link}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Fetch Prompt from Maxim\n",
                "\n",
                "Use `maxim.get_prompt()` to fetch a deployed prompt and run it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fetch prompt from Maxim using deployment variables\n",
                "prompt = maxim.get_prompt(\n",
                "    id=PROMPT_ID,\n",
                "    rule=QueryBuilder()\n",
                "        .and_()\n",
                "        .deployment_var(\"Environment\", \"prod\")\n",
                "        .build(),\n",
                ")\n",
                "\n",
                "if prompt:\n",
                "    print(f\"Fetched prompt: {prompt.name}\")\n",
                "    print(f\"Model: {prompt.model}\")\n",
                "    print(f\"Provider: {prompt.provider}\")\n",
                "else:\n",
                "    print(\"No matching prompt found\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def run_maxim_prompt(data: LocalData) -> YieldedOutput:\n",
                "    \"\"\"\n",
                "    Run the prompt fetched from Maxim.\n",
                "    \"\"\"\n",
                "    user_input = data.get(\"Input\") or data.get(\"input\") or \"\"\n",
                "    \n",
                "    # prompt.run() uses the model/provider configured in Maxim\n",
                "    response = prompt.run(user_input)\n",
                "    \n",
                "    return YieldedOutput(data=response.choices[0].message.content)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run test using the fetched prompt\n",
                "if prompt:\n",
                "    result = (\n",
                "        maxim.create_test_run(\n",
                "            name=\"Maxim Prompt Test\",\n",
                "            in_workspace_id=WORKSPACE_ID\n",
                "        )\n",
                "        .with_data(local_dataset)\n",
                "        .with_data_structure(data_structure)\n",
                "        .yields_output(run_maxim_prompt)\n",
                "        .with_evaluators(\"Clarity\", \"Output Relevance\")\n",
                "        .run()\n",
                "    )\n",
                "\n",
                "    print(f\"View results: {result.test_run_result.link}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you already know the prompt version ID, use `with_prompt_version_id()` instead of `yields_output()`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PROMPT_VERSION_ID = os.getenv(\"MAXIM_PROMPT_VERSION_ID\")\n",
                "\n",
                "# Run test with a specific prompt version\n",
                "result = (\n",
                "    maxim.create_test_run(\n",
                "        name=\"Prompt Version Test\",\n",
                "        in_workspace_id=WORKSPACE_ID\n",
                "    )\n",
                "    .with_data(local_dataset)\n",
                "    .with_data_structure(data_structure)\n",
                "    .with_prompt_version_id(PROMPT_VERSION_ID)  # Use prompt stored on Maxim\n",
                "    .with_evaluators(\"Clarity\", \"Output Relevance\")\n",
                "    .run()\n",
                ")\n",
                "\n",
                "print(f\"View results: {result.test_run_result.link}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Hosted Dataset and Prompt\n",
                "\n",
                "The simplest configuration - everything hosted on Maxim."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Everything hosted on Maxim\n",
                "result = (\n",
                "    maxim.create_test_run(\n",
                "        name=\"Fully Hosted Test\",\n",
                "        in_workspace_id=WORKSPACE_ID\n",
                "    )\n",
                "    .with_data(DATASET_ID)                      # Hosted dataset\n",
                "    .with_prompt_version_id(PROMPT_VERSION_ID)  # Hosted prompt\n",
                "    .with_evaluators(\"Clarity\", \"Bias\")         # Built-in evaluators\n",
                "    .run()\n",
                ")\n",
                "\n",
                "print(f\"View results: {result.test_run_result.link}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Related Resources\n",
                "\n",
                "- [Local Agent Testing](https://www.getmaxim.ai/docs/offline-evals/via-sdk/local-agent)\n",
                "- [Prompt Management](https://www.getmaxim.ai/docs/offline-evals/via-sdk/prompts/prompt-management)\n",
                "- [Datasets](https://www.getmaxim.ai/docs/library/datasets/import-or-create-datasets)\n",
                "- [Pre-built Evaluators](https://www.getmaxim.ai/docs/library/evaluators/pre-built-evaluators/overview)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
