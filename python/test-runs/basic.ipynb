{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Maxim SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from maxim import Config, Maxim\n",
    "\n",
    "config = dotenv_values()\n",
    "\n",
    "API_KEY: str = config.get(\"MAXIM_API_KEY\") or \"\"\n",
    "WORKSPACE_ID: str = config.get(\"MAXIM_WORKSPACE_ID\") or \"\"\n",
    "WORKFLOW_ID: str = config.get(\"MAXIM_WORKFLOW_ID\") or \"\"\n",
    "DATASET_ID: str = config.get(\"MAXIM_DATASET_ID\") or \"\"\n",
    "PROMPT_VERSION_ID: str = config.get(\"MAXIM_PROMPT_VERSION_ID\") or \"\"\n",
    "\n",
    "maxim = Maxim(config=Config(api_key=API_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and trigger test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating test run config...\n",
      "Sanitizing data...\n",
      "Sanitizing evaluators...\n",
      "Verifying if Bias is added to the workspace..\n",
      "Verifying if Clarity is added to the workspace..\n",
      "Creating test run: Basic test run from code\n",
      "You can view your test run here: https://app.getmaxim.ai/workspace/cln4nw1n80000mc3wqqwk4j0z/testrun/cm8en263400g8ycsfy518zn97\n",
      "You can safely quit this session or wait to see the final output in console.\n",
      "Waiting for test run to complete...\n",
      "Polling interval: 15 seconds\n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│                                                Test run status: QUEUED                                                │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ totalEntries: 0 | runningEntries: 0 | queuedEntries: 0 | failedEntries: 0 | completedEntries: 0 | stoppedEntries: 0   │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│                                                Test run status: RUNNING                                               │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ totalEntries: 4 | runningEntries: 4 | queuedEntries: 0 | failedEntries: 0 | completedEntries: 0 | stoppedEntries: 0   │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "┌───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
      "│                                               Test run status: COMPLETE                                               │\n",
      "├───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ totalEntries: 4 | runningEntries: 0 | queuedEntries: 0 | failedEntries: 0 | completedEntries: 4 | stoppedEntries: 0   │\n",
      "└───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
      "\n",
      "All entries processed. Test run completed.\n",
      "Test run \"Basic test run from code\" completed successfully!🎉 \n",
      "View the report here: https://app.getmaxim.ai/workspace/cln4nw1n80000mc3wqqwk4j0z/testrun/cm8en263400g8ycsfy518zn97\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RunResult(test_run_result=TestRunResult(link='https://app.getmaxim.ai/workspace/cln4nw1n80000mc3wqqwk4j0z/testrun/cm8en263400g8ycsfy518zn97', result=[TestRunResultObj(name='Basic test run from code', individual_evaluator_mean_score={'Clarity': EvaluatorMeanScore(score=0.94, out_of=1, is_pass=False), 'Bias': EvaluatorMeanScore(score=0, out_of=1, is_pass=True)}, usage=TestRunTokenUsage(total=0, input=0, completion=0), cost=TestRunCost(total=0, input=0, completion=0), latency=TestRunLatency(min=6355, max=14282.5625, p50=9799, p90=14287, p95=14287, p99=14287, mean=10487.5, standard_deviation=2873.8136, total=4))]), failed_entry_indices=[])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxim.create_test_run(\n",
    "    name=\"Basic test run from code\", in_workspace_id=WORKSPACE_ID\n",
    ").with_concurrency(2).with_data(DATASET_ID).with_workflow_id(\n",
    "    WORKFLOW_ID\n",
    ").with_evaluators(\n",
    "    \"Bias\", \"Clarity\"\n",
    ").run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
