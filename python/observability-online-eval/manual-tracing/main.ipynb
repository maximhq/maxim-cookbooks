{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Tracing of AI Code\n",
    "\n",
    "This notebook demonstrates how to trace AI code execution using Maxim's manual tracing approach. We'll analyze the code step by step to understand the flow and behavior of the AI system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Maxim logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[MaximSDK] Initializing Maxim AI(v3.6.2)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from maxim import Maxim\n",
    "\n",
    "# This automatically creates logger by reading MAXIM_API_KEY and MAXIM_LOG_REPO_ID from environment variables\n",
    "logger = Maxim({}).logger({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MaximSDK] Id is required. Entity: TRACE. Config: {'name': 'test-trace'}. We are generating a random id for you.\n"
     ]
    }
   ],
   "source": [
    "trace = logger.trace({\"name\": \"test-trace\"})\n",
    "trace.set_input(\"Hi!\")\n",
    "trace.set_output(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding an LLM call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MaximSDK] Id is required. Entity: GENERATION. Config: {'model': 'gpt-4o-mini', 'messages': [{'role': 'system', 'content': 'You are a helpful assistant.'}, {'role': 'user', 'content': 'Write a haiku about recursion in programming.'}]}. We are generating a random id for you.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code calls itself deep,  \n",
      "Functions nested, layers stack,  \n",
      "Endless loops embrace. CompletionUsage(completion_tokens=18, prompt_tokens=26, total_tokens=44, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"},\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Create a generation\n",
    "    generation = trace.generation({\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": messages,\n",
    "    })\n",
    "    # Create a chat completion request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,        \n",
    "    )\n",
    "    # Add result to the generation\n",
    "    generation.result(response)\n",
    "    # Extract response text and usage\n",
    "    response_text = response.choices[0].message.content\n",
    "    usage = response.usage    \n",
    "    print(response_text,usage)    \n",
    "except Exception as e:\n",
    "    # Add error to the generation\n",
    "    generation.error(e)\n",
    "finally:\n",
    "    generation.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a retrieval to the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "retrieval = trace.retrieval({\n",
    "    \"id\": str(uuid.uuid4()),\n",
    "})\n",
    "retrieval.input(\"What is the capital of France?\")\n",
    "retrieval.output(['{\\\"embedding_model_name\\\": \\\"text-embedding-ada-002\\\"}'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
