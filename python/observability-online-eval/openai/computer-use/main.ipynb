{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# One-Line Observability for Computer Use Agents with Maxim\n",
    "\n",
    "This notebook demonstrates how to add comprehensive observability to a Computer Use Agent (CUA) using Maxim's one-line integration. We'll show how easy it is to get full visibility into your agent's actions, decisions, and performance.\n",
    "\n",
    "## What You'll Learn\n",
    "- How to add observability to a LangGraph CUA with just one line of code\n",
    "- Understanding agent behavior through Maxim's tracing capabilities\n",
    "- Monitoring agent performance and debugging issues effectively\n",
    "- Capturing and analyzing agent interactions and decisions\n",
    "\n",
    "## Why Maxim for Agent Observability?\n",
    "- **Minimal Setup**: One-line integration with existing agent code\n",
    "- **Comprehensive Tracing**: Automatically capture all agent actions and decisions\n",
    "- **Debug with Ease**: Visualize agent workflow and identify issues quickly\n",
    "- **Performance Insights**: Monitor agent performance and behavior patterns\n",
    "\n",
    "## Prerequisites\n",
    "Before running this notebook, make sure you have:\n",
    "1. Set up your environment variables (see `.env.example`)\n",
    "   - `MAXIM_API_KEY`: Your Maxim API key\n",
    "   - `MAXIM_LOG_REPO_ID`: Your Maxim logger ID\n",
    "   - `OPENAI_API_KEY`: Your OpenAI API key\n",
    "   - `SCRAPYBARA_API_KEY`: Your Scrapybara API key\n",
    "2. Installed required dependencies (see `requirements.txt`)\n",
    "3. Access to OpenAI API (for the agent's underlying model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Maxim Observability\n",
    "\n",
    "First, let's set up Maxim for observability. This is the only setup required to get comprehensive tracing and monitoring for your agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from typing import List, Literal\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import LangGraph and LangChain components\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Import the Computer Use Agent components\n",
    "from langgraph_cua import create_cua\n",
    "from langgraph_cua.types import CUAState\n",
    "\n",
    "# The key imports for Maxim observability\n",
    "from maxim import Maxim\n",
    "from maxim.decorators.langchain import langchain_callback, langgraph_agent\n",
    "from maxim.decorators import trace, current_trace\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Maxim logger - This one line enables comprehensive observability\n",
    "logger = Maxim(\n",
    "    {\"api_key\": os.getenv(\"MAXIM_API_KEY\")}\n",
    ").logger({\"id\": os.getenv(\"MAXIM_LOG_REPO_ID\")})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Using the Computer Use Agent\n",
    "\n",
    "Now that we have Maxim set up, let's use the pre-built Computer Use Agent from LangGraph. The key here is that we'll wrap it with Maxim's decorators to get automatic tracing and observability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## What's Being Traced?\n",
    "\n",
    "When you run this notebook, Maxim automatically captures:\n",
    "\n",
    "1. **High-Level Operation**\n",
    "   - The entire agent interaction from start to finish\n",
    "   - Total execution time and status\n",
    "\n",
    "2. **LangGraph Operations**\n",
    "   - Node transitions in the agent workflow\n",
    "   - Routing decisions and their rationale\n",
    "   - Computer use actions and results\n",
    "\n",
    "3. **LangChain Operations**\n",
    "   - All LLM calls and their parameters\n",
    "   - Prompt templates and their rendered versions\n",
    "   - Token usage and costs\n",
    "\n",
    "4. **Custom Metrics**\n",
    "   - Input/output pairs at each step\n",
    "   - Any errors or exceptions\n",
    "   - Performance metrics\n",
    "\n",
    "All of this is available in your Maxim dashboard, with just the one-line setup and two decorators we added!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## State Definition\n",
    "\n",
    "First, we'll define our state class that extends the base CUA state. This class will handle the routing logic for our agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(CUAState):\n",
    "    \"\"\"State class for the research agent workflow, extending the CUA state.\n",
    "    This state tracks whether to use the computer for research or respond directly.\"\"\"\n",
    "    route: Literal[\"respond\", \"computer_use_agent\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Input Processing\n",
    "\n",
    "Next, we'll define the function that processes user input and determines whether to route to the computer use agent or generate a direct response. This function uses GPT-4 to make the routing decision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(state: ResearchState):\n",
    "    \"\"\"\n",
    "    Analyzes the user's latest message and determines whether to route to the\n",
    "    computer use agent or to generate a direct response.\n",
    "    \"\"\"\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You're an advanced AI assistant tasked with routing the user's query to the appropriate node.\"\n",
    "            \"Your options are: computer use or respond. You should pick computer use if the user's request requires \"\n",
    "            \"using a computer (e.g. looking up a price on a website, or do a websearch), and pick respond for ANY other inputs.\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    class RoutingToolSchema(BaseModel):\n",
    "        \"\"\"Route the user's request to the appropriate node.\"\"\"\n",
    "        route: Literal[\"respond\", \"computer_use_agent\"] = Field(\n",
    "            ...,\n",
    "            description=\"The node to route to, either 'computer_use_agent' for any input which might require using a computer to assist the user, or 'respond' for any other input\",\n",
    "        )\n",
    "\n",
    "    model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    model_with_tools = model.with_structured_output(RoutingToolSchema)\n",
    "\n",
    "    user_messages = state.get(\"messages\", [])\n",
    "    if not user_messages:\n",
    "        return {\"route\": \"respond\"}  # Default to respond if no messages\n",
    "\n",
    "    messages = [system_message, {\"role\": \"user\", \"content\": user_messages[-1].content}]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"route\": response.route}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Response Generation\n",
    "\n",
    "Now we'll define the function that generates responses when the routing decision is to respond directly (without using the computer).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(state: ResearchState):\n",
    "    \"\"\"\n",
    "    Generates a general response to the user based on the entire conversation history.\n",
    "    \"\"\"\n",
    "    def format_messages(messages: List[AnyMessage]) -> str:\n",
    "        \"\"\"Formats a list of messages into a single string with type and content.\"\"\"\n",
    "        return \"\\n\".join([f\"{message.type}: {message.content}\" for message in messages])\n",
    "\n",
    "    system_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You're an advanced AI assistant tasked with responding to the user's input.\"\n",
    "            \"You're provided with the full conversation between the user, and the AI assistant. \"\n",
    "            \"This conversation may include messages from a computer use agent, along with \"\n",
    "            \"general user inputs and AI responses. \\n\\n\"\n",
    "            \"Given all of this, please RESPOND to the user. If there is nothing to respond to, you may return something like 'Let me know if you have any other questions.'\"\n",
    "        ),\n",
    "    }\n",
    "    human_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Here are all of the messages in the conversation:\\n\\n\"\n",
    "        + format_messages(state.get(\"messages\")),\n",
    "    }\n",
    "\n",
    "    model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "    response = model.invoke([system_message, human_message])\n",
    "    \n",
    "    return {\"response\": response}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Graph Construction\n",
    "\n",
    "Now we'll construct the LangGraph workflow that ties everything together. This includes:\n",
    "1. Creating the state graph\n",
    "2. Adding nodes for input processing, response generation, and computer use\n",
    "3. Setting up the edges between nodes\n",
    "4. Compiling the graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CUA graph\n",
    "cua_graph = create_cua()\n",
    "\n",
    "def route_after_processing_input(state: ResearchState):\n",
    "    \"\"\"Conditional router that returns the route determined by process_input.\"\"\"\n",
    "    return state.get(\"route\")\n",
    "\n",
    "# Create and configure the workflow\n",
    "workflow = StateGraph(ResearchState)\n",
    "workflow.add_node(\"process_input\", process_input)\n",
    "workflow.add_node(\"respond\", respond)\n",
    "workflow.add_node(\"computer_use_agent\", cua_graph)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"process_input\")\n",
    "workflow.add_conditional_edges(\"process_input\", route_after_processing_input)\n",
    "workflow.add_edge(\"respond\", END)\n",
    "workflow.add_edge(\"computer_use_agent\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = workflow.compile()\n",
    "graph.name = \"Research Agent\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Agent Interface\n",
    "\n",
    "Finally, we'll create the interface for interacting with our agent. This includes:\n",
    "1. A decorated function for handling agent requests\n",
    "2. Proper integration with Maxim for observability\n",
    "3. Asynchronous execution support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@langgraph_agent(name=\"research-agent-v1\")\n",
    "async def ask_agent(messages):\n",
    "    config = {\"recursion_limit\": 50, \"callbacks\": [langchain_callback()]}\n",
    "    stream = graph.astream({\"messages\": messages}, subgraphs=True, stream_mode=\"updates\", config=config)\n",
    "    last_update = None\n",
    "    async for update in stream:\n",
    "        if \"computer_use_agent\" in update[1]:\n",
    "            last_update = update[1][\"computer_use_agent\"].get(\"messages\", {})\n",
    "    return last_update\n",
    "\n",
    "@trace(logger=logger, name=\"research-agent-v1\")\n",
    "async def handle(messages) -> str:\n",
    "    response = await ask_agent(messages)\n",
    "    if isinstance(response, str):\n",
    "        current_trace().set_output(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Example Usage\n",
    "\n",
    "Let's try out our Computer Use Agent with a simple example: finding today's top song on Billboard's charts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Run the agent workflow.\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You're an advanced AI computer use assistant. The browser you are using \"\n",
    "                \"is already initialized, and visiting google.com.\"\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"find today's top 1 song on billboard's charts.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    await handle(messages)\n",
    "\n",
    "# Run the example\n",
    "await main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observability in Action\n",
    "\n",
    "Let's look at what Maxim's observability provides when running our Research Agent. Below are some key visualizations from the Maxim dashboard:\n",
    "\n",
    "### 1. Full Trace Overview\n",
    "![Trace Overview](./assets/image_1.png)\n",
    "This shows the complete trace of our agent's execution, including all steps from initial request to final response along with the associated costs and latency.\n",
    "\n",
    "### 2. Precise Metadata Extraction\n",
    "![Metadata](./assets/image_2.png)\n",
    "Here you can see how Maxim captures relevant metadata precisely, including but not limited to token usage and the LLM being called.\n",
    "\n",
    "### 3. Computer Use Actions\n",
    "![Computer Use](./assets/image_3.png)\n",
    "This visualization shows the actual computer use actions being performed by our agent when researching information, which is a click at the given captured instant.\n",
    "\n",
    "### 4. Performance Metrics\n",
    "![Performance](./assets/image_4.png)\n",
    "Screenshots at every step of the agents trajectory get logged!\n",
    "\n",
    "These visualizations help us:\n",
    "- Debug agent behavior and decision-making\n",
    "- Monitor performance and resource usage\n",
    "- Track successful vs failed interactions\n",
    "- Identify optimization opportunities\n",
    "\n",
    "And remember - all of this observability came from just:\n",
    "1. One line of logger initialization\n",
    "2. Two decorators (`@langgraph_agent` and `@trace`)\n",
    "3. A callback configuration\n",
    "\n",
    "No manual instrumentation or complex setup required!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
