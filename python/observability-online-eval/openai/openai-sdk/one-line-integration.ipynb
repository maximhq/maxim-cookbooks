{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual tracing for OpenAI LLM calls using Maxim SDK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from maxim import Maxim\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Set up Maxim logger configuration\n",
    "logger = Maxim().logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a trace and add it to the session\n",
    "\n",
    "A trace represents one round trip between user <-> agent. More info [here]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from maxim.logger.openai import MaximOpenAIClient\n",
    "\n",
    "client = MaximOpenAIClient(client=OpenAI(api_key=OPENAI_API_KEY),logger=logger)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about recursion in programming.\"},\n",
    "]\n",
    "\n",
    "# Create a chat completion request\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,                    \n",
    ")\n",
    "# Extract response text and usage\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With completions parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# Define the response structure using Pydantic\n",
    "class HaikuAnalysis(BaseModel):\n",
    "    haiku: str\n",
    "    syllable_count: List[int]  # syllables per line\n",
    "    theme: str\n",
    "    mood: str\n",
    "    follows_5_7_5_pattern: bool\n",
    "\n",
    "# Use chat.completions.parse for structured output\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetry expert. Analyze haikus and return structured data.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about bifrost and analyze it.\"},\n",
    "]\n",
    "\n",
    "# Create a structured completion request using parse\n",
    "response = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    response_format=HaikuAnalysis,\n",
    ")\n",
    "\n",
    "# Extract the parsed response\n",
    "parsed_response = response.choices[0].message.parsed\n",
    "print(\"Parsed Haiku Analysis:\")\n",
    "print(f\"Haiku: {parsed_response.haiku}\")\n",
    "print(f\"Syllable Count: {parsed_response.syllable_count}\")\n",
    "print(f\"Theme: {parsed_response.theme}\")\n",
    "print(f\"Mood: {parsed_response.mood}\")\n",
    "print(f\"Follows 5-7-5 Pattern: {parsed_response.follows_5_7_5_pattern}\")\n",
    "\n",
    "# You can also access the raw content\n",
    "print(\"\\nRaw JSON:\")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Another example: Recipe extraction with structured output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from enum import Enum\n",
    "\n",
    "class DifficultyLevel(str, Enum):\n",
    "    EASY = \"easy\"\n",
    "    MEDIUM = \"medium\"\n",
    "    HARD = \"hard\"\n",
    "\n",
    "class Ingredient(BaseModel):\n",
    "    name: str\n",
    "    amount: str\n",
    "    unit: Optional[str] = None\n",
    "\n",
    "class Recipe(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    prep_time_minutes: int\n",
    "    cook_time_minutes: int\n",
    "    servings: int\n",
    "    difficulty: DifficultyLevel\n",
    "    ingredients: List[Ingredient]\n",
    "    instructions: List[str]\n",
    "    tags: List[str]\n",
    "\n",
    "# Request a recipe with structured output\n",
    "recipe_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a professional chef. Create detailed recipes with precise measurements and clear instructions.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Create a recipe for chocolate chip cookies that's suitable for beginners.\"},\n",
    "]\n",
    "\n",
    "recipe_response = client.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=recipe_messages,\n",
    "    response_format=Recipe,\n",
    ")\n",
    "\n",
    "# Extract and display the structured recipe\n",
    "recipe = recipe_response.choices[0].message.parsed\n",
    "\n",
    "print(f\"Recipe: {recipe.name}\")\n",
    "print(f\"Description: {recipe.description}\")\n",
    "print(f\"Prep Time: {recipe.prep_time_minutes} minutes\")\n",
    "print(f\"Cook Time: {recipe.cook_time_minutes} minutes\")\n",
    "print(f\"Servings: {recipe.servings}\")\n",
    "print(f\"Difficulty: {recipe.difficulty.value}\")\n",
    "\n",
    "print(\"\\nIngredients:\")\n",
    "for ingredient in recipe.ingredients:\n",
    "    unit_text = f\" {ingredient.unit}\" if ingredient.unit else \"\"\n",
    "    print(f\"- {ingredient.amount}{unit_text} {ingredient.name}\")\n",
    "\n",
    "print(\"\\nInstructions:\")\n",
    "for i, instruction in enumerate(recipe.instructions, 1):\n",
    "    print(f\"{i}. {instruction}\")\n",
    "\n",
    "print(f\"\\nTags: {', '.join(recipe.tags)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with error handling and validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field, validator\n",
    "from datetime import datetime\n",
    "\n",
    "class EventDetails(BaseModel):\n",
    "    title: str = Field(..., min_length=1, max_length=100)\n",
    "    date: str = Field(..., description=\"Date in YYYY-MM-DD format\")\n",
    "    time: str = Field(..., description=\"Time in HH:MM format (24-hour)\")\n",
    "    location: str\n",
    "    attendees: int = Field(..., ge=1, le=1000)  # Between 1 and 1000 attendees\n",
    "    category: str = Field(..., description=\"Event category\")\n",
    "    is_virtual: bool = False\n",
    "    \n",
    "    @validator('date')\n",
    "    def validate_date_format(cls, v):\n",
    "        try:\n",
    "            datetime.strptime(v, '%Y-%m-%d')\n",
    "            return v\n",
    "        except ValueError:\n",
    "            raise ValueError('Date must be in YYYY-MM-DD format')\n",
    "    \n",
    "    @validator('time')\n",
    "    def validate_time_format(cls, v):\n",
    "        try:\n",
    "            datetime.strptime(v, '%H:%M')\n",
    "            return v\n",
    "        except ValueError:\n",
    "            raise ValueError('Time must be in HH:MM format (24-hour)')\n",
    "\n",
    "# Example with error handling\n",
    "try:\n",
    "    event_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an event planning assistant. Create event details with proper formatting.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Plan a tech conference for next month with about 200 attendees in San Francisco.\"},\n",
    "    ]\n",
    "    \n",
    "    event_response = client.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=event_messages,\n",
    "        response_format=EventDetails,\n",
    "    )\n",
    "    \n",
    "    # Check if parsing was successful\n",
    "    if event_response.choices[0].message.parsed:\n",
    "        event = event_response.choices[0].message.parsed\n",
    "        print(\"✅ Successfully parsed event details:\")\n",
    "        print(f\"Title: {event.title}\")\n",
    "        print(f\"Date: {event.date}\")\n",
    "        print(f\"Time: {event.time}\")\n",
    "        print(f\"Location: {event.location}\")\n",
    "        print(f\"Attendees: {event.attendees}\")\n",
    "        print(f\"Category: {event.category}\")\n",
    "        print(f\"Virtual: {event.is_virtual}\")\n",
    "    else:\n",
    "        print(\"❌ Failed to parse the response\")\n",
    "        print(\"Raw content:\", event_response.choices[0].message.content)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "    print(\"This might happen if the model fails to generate valid structured output\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
