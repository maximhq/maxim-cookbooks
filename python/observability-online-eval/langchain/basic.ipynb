{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain + OpenAI LLM tracing using Maxim + Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "LOG_REPOSITORY_ID = os.getenv(\"MAXIM_LOG_REPO_ID\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will initialize MaximLangchainTracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[MaximSDK] Using global logging level\u001b[0m\n",
      "\u001b[32m[MaximSDK] Initializing Maxim AI(v3.5.6)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p0/3mgzlyg541g1j9s2d1wskc040000gn/T/ipykernel_48866/944686778.py:3: DeprecationWarning: This class will be removed in a future version. Use ConfigDict instead.\n",
      "  logger = Maxim(Config()).logger(LoggerConfig(id=LOG_REPOSITORY_ID))\n",
      "/var/folders/p0/3mgzlyg541g1j9s2d1wskc040000gn/T/ipykernel_48866/944686778.py:3: DeprecationWarning: This class will be removed in a future version. Use LoggerConfigDict instead.\n",
      "  logger = Maxim(Config()).logger(LoggerConfig(id=LOG_REPOSITORY_ID))\n"
     ]
    }
   ],
   "source": [
    "from maxim import Maxim, Config, LoggerConfig\n",
    "\n",
    "logger = Maxim(Config()).logger(LoggerConfig(id=LOG_REPOSITORY_ID))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up langchain call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Big Bang Theory is a scientific explanation for the origin and evolution of the universe. According to this theory, the universe began approximately 13.8 billion years ago from an extremely hot and dense state, often referred to as a singularity, and has been expanding ever since.\n",
      "\n",
      "Here are some key points about the Big Bang Theory:\n",
      "\n",
      "1. **Singularity**: The theory posits that the universe originated from a singularity, a point of infinite density and temperature, where the known laws of physics break down.\n",
      "\n",
      "2. **Expansion of the Universe**: After the initial explosion or expansion, the universe began to cool and expand. This expansion continues today, which means galaxies are moving away from each other.\n",
      "\n",
      "3. **Cosmic Microwave Background (CMB)**: One of the strongest pieces of evidence for the Big Bang Theory is the cosmic microwave background radiation. This is the thermal radiation left over from the time of recombination, about 380,000 years after the Big Bang, when electrons and protons first combined to form neutral hydrogen atoms, allowing light to travel freely.\n",
      "\n",
      "4. **Formation of Elements**: In the first few minutes after the Big Bang, nucleosynthesis occurred, leading to the formation of light elements like hydrogen, helium, and small amounts of lithium and beryllium. This process is known as Big Bang nucleosynthesis.\n",
      "\n",
      "5. **Galaxy Formation and Structure**: As the universe expanded and cooled, matter began to coalesce under the influence of gravity, leading to the formation of stars, galaxies, and larger structures.\n",
      "\n",
      "6. **Redshift of Galaxies**: Observations show that light from distant galaxies is redshifted, meaning it has been stretched to longer wavelengths as the universe expands. This redshift is interpreted as evidence that the universe is expanding.\n",
      "\n",
      "7. **Inflation**: The theory includes a brief period of rapid expansion known as cosmic inflation, which occurred within the first fraction of a second after the Big Bang. Inflation helps explain the uniformity of the CMB and the large-scale structure of the universe.\n",
      "\n",
      "Overall, the Big Bang Theory is supported by extensive observational evidence and is the prevailing cosmological model for explaining the universe's beginnings and its large-scale structure. However, it is important to note that the theory does not explain what caused the Big Bang or what might have occurred before it.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from maxim.logger.langchain import MaximLangchainTracer\n",
    "\n",
    "langchain_tracer = MaximLangchainTracer(logger)\n",
    "\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "llm = ChatOpenAI(model=MODEL_NAME, api_key=OPENAI_API_KEY)\n",
    "\n",
    "user_input = \"Describe big bang theory\"\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "# Make the API call to Claude using LangChain\n",
    "messages = [(\"system\", system_message), (\"human\", user_input)]\n",
    "response = llm.invoke(messages,config={\"callbacks\":[langchain_tracer]})\n",
    "response_text = response.content\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_tracer = MaximLangchainTracer(logger)\n",
    "\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "llm = ChatOpenAI(model=MODEL_NAME, api_key=OPENAI_API_KEY, streaming=True)\n",
    "\n",
    "user_input = \"Describe big bang theory\"\n",
    "system_message = \"You are a helpful assistant.\"\n",
    "# Make the API call using LangChain with streaming\n",
    "messages = [(\"system\", system_message), (\"human\", user_input)]\n",
    "\n",
    "# Stream the response\n",
    "response_text = \"\"\n",
    "for chunk in llm.stream(messages, config={\"callbacks\":[langchain_tracer]}):\n",
    "    pass\n",
    "\n",
    "print(\"\\n\\nFull response:\", response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
