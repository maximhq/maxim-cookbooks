{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LiteLLM Integration with Maxim SDK Tracing\n",
    "\n",
    "This tutorial demonstrates how to integrate Maxim SDK tracing capabilities with LiteLLM. You'll learn how to set up and configure Maxim's tracing functionality to monitor and analyze your LiteLLM API calls, providing valuable insights into your LLM application's performance and usage patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initializing Maxim SDK and adding as a logger in litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[MaximSDK] Litellm support is in beta\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "import os\n",
    "from maxim import Maxim, Config, LoggerConfig\n",
    "from maxim.logger.litellm import MaximLiteLLMTracer\n",
    "\n",
    "logger = Maxim(Config()).logger(LoggerConfig(id=os.getenv(\"MAXIM_LOG_REPO_ID\")))\n",
    "# This is the single line integration of Maxim SDK with LiteLLM\n",
    "litellm.callbacks = [MaximLiteLLMTracer(logger)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initializing litellm router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from litellm import acompletion\n",
    "\n",
    "response = await acompletion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hello, world!\"}],        \n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaching a custom trace to the litellm generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can assist you with a wide range of tasks and inquiries, such as:\n",
      "\n",
      "1. **Answer Questions**: Provide information and answer questions on various topics, including science, history, technology, and more.\n",
      "2. **Recommendations**: Suggest books, movies, games, or other media based on your interests.\n",
      "3. **General Advice**: Offer basic advice on topics like studying, organizing, or managing time effectively.\n",
      "4. **Writing Assistance**: Help with writing tasks such as composing emails, grammar checking, brainstorming ideas, and structuring documents.\n",
      "5. **Educational Support**: Aid in understanding complex topics or solving problems in subjects like math or science.\n",
      "6. **Cooking Tips**: Suggest recipes and cooking techniques.\n",
      "7. **Language Help**: Assist with translations, learning new words, or understanding language rules.\n",
      "8. **Tech Troubleshooting**: Help with basic tech support or troubleshooting common device issues.\n",
      "9. **News Summaries**: Provide summaries of recent news events (up to my last update) and historical context.\n",
      "10. **Creative Projects**: Help brainstorm or refine ideas for creative projects, such as stories or art.\n",
      "\n",
      "If you have a specific question or need, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from maxim.logger.logger import TraceConfig\n",
    "import uuid\n",
    "\n",
    "trace = logger.trace(TraceConfig(id=str(uuid.uuid4()), name=\"litellm-generation\"))\n",
    "trace.event(str(uuid.uuid4()), \"litellm-generation\", \"litellm-generation\", {})\n",
    "# This will attach litellm generation to the trace inside a span.\n",
    "response = await acompletion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "        messages=[{\"role\": \"user\", \"content\": \"What can you do for me!\"}],        \n",
    "        metadata={\"maxim\": {\"trace_id\": trace.id, \"span_name\": \"litellm-generation\"}}\n",
    "    )\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![LiteLLM Custom Trace](images/litellm-custom-trace.png)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
